{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#TWITTER DATA ANALYTICS + VISUALIZATION\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from textblob import TextBlob\n",
        "import re\n",
        "\n",
        "twitter_data = {\n",
        "    'tweet_id': [1, 2, 3, 4, 5],\n",
        "    'tweet_text': [\n",
        "        \"Just watched Avengers: Endgame. It was amazing!\",\n",
        "        \"The new Spider-Man movie was disappointing.\",\n",
        "        \"Excited to see the upcoming James Bond movie!\",\n",
        "        \"I can't believe how bad the last Transformers movie was.\",\n",
        "        \"The Joker movie was a masterpiece.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(twitter_data)\n",
        "\n",
        "# Perform sentiment analysis\n",
        "def analyze_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    polarity = analysis.sentiment.polarity\n",
        "    if polarity > 0:\n",
        "        return 'positive'\n",
        "    elif polarity < 0:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "df['sentiment'] = df['tweet_text'].apply(analyze_sentiment)\n",
        "\n",
        "sentiment_counts = df['sentiment'].value_counts()\n",
        "plt.bar(sentiment_counts.index, sentiment_counts.values)\n",
        "plt.title('Sentiment Analysis of Movie Tweets')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "word_freq = {}\n",
        "for tweet in df['tweet_text']:\n",
        "    words = re.findall(r'\\b\\w+\\b', tweet.lower())\n",
        "    for word in words:\n",
        "        if word in word_freq:\n",
        "            word_freq[word] += 1\n",
        "        else:\n",
        "            word_freq[word] = 1\n",
        "\n",
        "sorted_word_freq = dict(sorted(word_freq.items(), key=lambda item: item[1], reverse=True)[:10])\n",
        "plt.bar(sorted_word_freq.keys(), sorted_word_freq.values())\n",
        "plt.title('Top Words in Movie Tweets')\n",
        "plt.xlabel('Word')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "n0oioZq4GspS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOCATION ANALYSIS\n",
        "# CSV:\n",
        "# tweet,location\n",
        "# \"I love my new iPhone from Apple!\",New York\n",
        "# \"The hotel service was excellent during my stay.\",Los Angeles\n",
        "# \"Excited for the upcoming G20 summit.\",London\n",
        "# \"Just watched Titanic, Leonardo DiCaprio's acting was amazing.\",Chicago\n",
        "# \"Enjoying a lovely day in Paris.\",Paris\n",
        "# \"Can't wait to visit the new Apple store.\",San Francisco\n",
        "# \"I had a great experience at the hotel spa.\",Miami\n",
        "# \"Discussions at the G20 are crucial for global cooperation.\",London\n",
        "# \"Leonardo DiCaprio is my favorite actor.\",Los Angeles\n",
        "# \"Missing the beautiful streets of Paris.\",Paris\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "file_path = 'twitter_location_data.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "location_counts = df['location'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "location_counts.plot(kind='bar', color='skyblue')\n",
        "plt.title('Distribution of Tweets by Location')\n",
        "plt.xlabel('Location')\n",
        "plt.ylabel('Number of Tweets')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-dTmHv9AW8bP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HASHTAG POPULARITY\n",
        "# CSV:\n",
        "# tweet,hashtags\n",
        "# \"I love my new iPhone from Apple!\",\"#happy #technology #Apple\"\n",
        "# \"The hotel service was excellent during my stay.\",\"#hotel #service #recommendation\"\n",
        "# \"Excited for the upcoming G20 summit.\",\"#G20 #politics #global\"\n",
        "# \"Just watched Titanic, Leonardo DiCaprio's acting was amazing.\",\"#movie #actor #LeonardoDiCaprio\"\n",
        "# \"Enjoying a lovely day in Paris.\",\"#Paris #travel #city\"\n",
        "# \"Can't wait to visit the new Apple store.\",\"#shopping #Apple #excited\"\n",
        "# \"I had a great experience at the hotel spa.\",\"#relaxation #spa #hotel\"\n",
        "# \"Discussions at the G20 are crucial for global cooperation.\",\"#G20 #discussion #global\"\n",
        "# \"Leonardo DiCaprio is my favorite actor.\",\"#actor #favorite #LeonardoDiCaprio\"\n",
        "# \"Missing the beautiful streets of Paris.\",\"#Paris #nostalgia #travel\"\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "file_path = 'twitter_hashtag_data.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "hashtags_list = df['hashtags'].str.split()\n",
        "\n",
        "hashtags_count = {}\n",
        "for hashtags in hashtags_list:\n",
        "    for hashtag in hashtags:\n",
        "        if hashtag.startswith('#'):\n",
        "            hashtag = hashtag.lower()\n",
        "            if hashtag in hashtags_count:\n",
        "                hashtags_count[hashtag] += 1\n",
        "            else:\n",
        "                hashtags_count[hashtag] = 1\n",
        "\n",
        "sorted_hashtags = sorted(hashtags_count.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"Most popular hashtags:\")\n",
        "for hashtag, count in sorted_hashtags:\n",
        "    print(f\"{hashtag}: {count}\")\n"
      ],
      "metadata": {
        "id": "XNo5M0FwXKuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SENTIMENT\n",
        "# import pandas as pd\n",
        "# from textblob import TextBlob\n",
        "\n",
        "# file_path = '/content/twitter.csv'\n",
        "# df = pd.read_csv(file_path)\n",
        "\n",
        "# sentiments = []\n",
        "# for tweet in df['tweet']:\n",
        "#     analysis = TextBlob(tweet)\n",
        "#     polarity = analysis.sentiment.polarity\n",
        "#     if polarity > 0:\n",
        "#         sentiment = 'positive'\n",
        "#     elif polarity < 0:\n",
        "#         sentiment = 'negative'\n",
        "#     else:\n",
        "#         sentiment = 'neutral'\n",
        "#     sentiments.append(sentiment)\n",
        "\n",
        "# df['sentiment'] = sentiments\n",
        "\n",
        "# print(df)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file containing Twitter data\n",
        "file_path = '/content/twitter.csv'  # Replace with the path to your CSV file\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Define a function to classify sentiment\n",
        "def classify_sentiment(text):\n",
        "    # Predefined rules for sentiment classification\n",
        "    positive_words = ['love', 'great', 'excellent', 'happy', 'excited', 'awesome']\n",
        "    negative_words = ['hate', 'bad', 'terrible', 'disappointed', 'awful']\n",
        "\n",
        "    # Tokenize the text and convert to lowercase\n",
        "    words = text.lower().split()\n",
        "\n",
        "    # Count positive and negative words\n",
        "    positive_count = sum(1 for word in words if word in positive_words)\n",
        "    negative_count = sum(1 for word in words if word in negative_words)\n",
        "\n",
        "    # Classify sentiment\n",
        "    if positive_count > negative_count:\n",
        "        return 'positive'\n",
        "    elif negative_count > positive_count:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "# Perform sentiment analysis on each tweet\n",
        "sentiments = []\n",
        "for tweet in df['tweet']:\n",
        "    sentiment = classify_sentiment(tweet)\n",
        "    sentiments.append(sentiment)\n",
        "\n",
        "# Add the sentiment column to the DataFrame\n",
        "df['sentiment'] = sentiments\n",
        "\n",
        "# Display the DataFrame with sentiment analysis results\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEmAAVGQYJXO",
        "outputId": "c820131d-3cb9-4703-e0c2-ff3c0ed3a13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweet sentiment\n",
            "0                   I love my new iPhone from Apple!  positive\n",
            "1    The hotel service was excellent during my stay.  positive\n",
            "2               Excited for the upcoming G20 summit.  positive\n",
            "3  Just watched Titanic, Leonardo DiCaprio's acti...   neutral\n",
            "4                    Enjoying a lovely day in Paris.   neutral\n",
            "5           Can't wait to visit the new Apple store.   neutral\n",
            "6         I had a great experience at the hotel spa.  positive\n",
            "7  Discussions at the G20 are crucial for global ...   neutral\n",
            "8            Leonardo DiCaprio is my favorite actor.   neutral\n",
            "9            Missing the beautiful streets of Paris.   neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TWITTER + GOOGLE\n",
        "# TWITTER DATA:\n",
        "# tweet_id,tweet_text,user_id,user_location,created_at\n",
        "# 1,\"Great experience at XYZ store! #happy\",1001,New York,2024-04-01\n",
        "# 2,\"Disappointed with the service at ABC restaurant. #unhappy\",1002,Los Angeles,2024-04-02\n",
        "# 3,\"Just bought a new product from XYZ brand. #excited\",1003,Chicago,2024-04-03\n",
        "# 4,\"Lovely weather today! #beautiful\",1004,San Francisco,2024-04-04\n",
        "# 5,\"Attended the G20 summit. Interesting discussions. #G20\",1005,Washington DC,2024-04-05\n",
        "\n",
        "# GOOGLE DATA:\n",
        "# review_id,review_text,user_id,user_location,rating,review_date\n",
        "# 1,\"Great food and service!\",2001,New York,5,2024-03-30\n",
        "# 2,\"Disappointed with the quality.\",2002,Los Angeles,2,2024-03-31\n",
        "# 3,\"Highly recommend this place!\",2003,Chicago,5,2024-04-01\n",
        "# 4,\"Average experience.\",2004,San Francisco,3,2024-04-02\n",
        "# 5,\"Excellent customer support.\",2005,Miami,5,2024-04-03\n",
        "\n",
        "# EXPLORATORY\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "twitter_df = pd.read_csv('dummy_twitter_data.csv')\n",
        "google_reviews_df = pd.read_csv('dummy_google_reviews_data.csv')\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=twitter_df, x='user_location')\n",
        "plt.title('Distribution of Tweets by User Location')\n",
        "plt.xlabel('User Location')\n",
        "plt.ylabel('Number of Tweets')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(data=google_reviews_df, x='rating')\n",
        "plt.title('Distribution of Ratings')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Brand Analysis (Twitter Sentiment Analysis):\n",
        "from textblob import TextBlob\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    polarity = analysis.sentiment.polarity\n",
        "    if polarity > 0:\n",
        "        return 'positive'\n",
        "    elif polarity < 0:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "twitter_df['sentiment'] = twitter_df['tweet_text'].apply(analyze_sentiment)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(data=twitter_df, x='sentiment')\n",
        "plt.title('Sentiment Analysis of Tweets')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#User Engagement Analysis and Visualization:\n",
        "import numpy as np\n",
        "\n",
        "twitter_df['retweets'] = np.random.randint(0, 100, size=len(twitter_df))\n",
        "twitter_df['likes'] = np.random.randint(0, 100, size=len(twitter_df))\n",
        "twitter_df['replies'] = np.random.randint(0, 100, size=len(twitter_df))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=twitter_df, x='tweet_id', y='retweets', color='skyblue', label='Retweets')\n",
        "sns.barplot(data=twitter_df, x='tweet_id', y='likes', color='orange', label='Likes')\n",
        "sns.barplot(data=twitter_df, x='tweet_id', y='replies', color='green', label='Replies')\n",
        "plt.title('User Engagement Analysis')\n",
        "plt.xlabel('Tweet ID')\n",
        "plt.ylabel('Count')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "fxDGJL59ESuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SOCIAL NETWORK GRAPH\n",
        "# import networkx as nx\n",
        "# import matplotlib.pyplot as plt\n",
        "# import random\n",
        "\n",
        "# num_nodes = 20\n",
        "# num_edges = 30\n",
        "# G = nx.gnm_random_graph(num_nodes, num_edges)\n",
        "\n",
        "# nx.draw(G, with_labels=True)\n",
        "# plt.title('Random Social Network Graph')\n",
        "# plt.show()\n",
        "\n",
        "# # Degree Centrality\n",
        "# degree_centrality = nx.degree_centrality(G)\n",
        "\n",
        "# print(\"Degree Centrality:\")\n",
        "# for node, centrality in degree_centrality.items():\n",
        "#     print(f\"Node {node}: {centrality}\")\n",
        "\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "G = nx.Graph()\n",
        "\n",
        "nodes = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\", \"Frank\", \"Grace\"]\n",
        "G.add_nodes_from(nodes)\n",
        "\n",
        "edges = [(\"Alice\", \"Bob\"), (\"Alice\", \"Charlie\"), (\"Alice\", \"David\"),\n",
        "         (\"Bob\", \"David\"), (\"Bob\", \"Eve\"), (\"Charlie\", \"David\"),\n",
        "         (\"David\", \"Eve\"), (\"David\", \"Frank\"), (\"Eve\", \"Frank\"),\n",
        "         (\"Eve\", \"Grace\")]\n",
        "G.add_edges_from(edges)\n",
        "\n",
        "nx.draw(G, with_labels=True)\n",
        "plt.title('Social Network Graph')\n",
        "plt.show()\n",
        "\n",
        "# Degree Centrality\n",
        "degree_centrality = nx.degree_centrality(G)\n",
        "\n",
        "print(\"Degree Centrality:\")\n",
        "for node, centrality in degree_centrality.items():\n",
        "    print(f\"Node {node}: {centrality}\")\n",
        "\n",
        "# Betweenness Centrality\n",
        "betweenness_centrality = nx.betweenness_centrality(G)\n",
        "\n",
        "print(\"\\nBetweenness Centrality:\")\n",
        "for node, centrality in betweenness_centrality.items():\n",
        "    print(f\"Node {node}: {centrality}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Mp9MqHX7Fj6a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}