# -*- coding: utf-8 -*-
"""Untitled.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mfojLKvCim5ABFP27eQbyXDwQVvzSNOM
"""

#TWITTER DATA ANALYTICS + VISUALIZATION
import pandas as pd
import matplotlib.pyplot as plt
from textblob import TextBlob
import re

twitter_data = {
    'tweet_id': [1, 2, 3, 4, 5],
    'tweet_text': [
        "Just watched Avengers: Endgame. It was amazing!",
        "The new Spider-Man movie was disappointing.",
        "Excited to see the upcoming James Bond movie!",
        "I can't believe how bad the last Transformers movie was.",
        "The Joker movie was a masterpiece."
    ]
}

df = pd.DataFrame(twitter_data)

# Perform sentiment analysis
def analyze_sentiment(text):
    analysis = TextBlob(text)
    polarity = analysis.sentiment.polarity
    if polarity > 0:
        return 'positive'
    elif polarity < 0:
        return 'negative'
    else:
        return 'neutral'

df['sentiment'] = df['tweet_text'].apply(analyze_sentiment)

sentiment_counts = df['sentiment'].value_counts()
plt.bar(sentiment_counts.index, sentiment_counts.values)
plt.title('Sentiment Analysis of Movie Tweets')
plt.xlabel('Sentiment')
plt.ylabel('Count')
plt.show()

word_freq = {}
for tweet in df['tweet_text']:
    words = re.findall(r'\b\w+\b', tweet.lower())
    for word in words:
        if word in word_freq:
            word_freq[word] += 1
        else:
            word_freq[word] = 1

sorted_word_freq = dict(sorted(word_freq.items(), key=lambda item: item[1], reverse=True)[:10])
plt.bar(sorted_word_freq.keys(), sorted_word_freq.values())
plt.title('Top Words in Movie Tweets')
plt.xlabel('Word')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.show()

# LOCATION ANALYSIS
# CSV:
# tweet,location
# "I love my new iPhone from Apple!",New York
# "The hotel service was excellent during my stay.",Los Angeles
# "Excited for the upcoming G20 summit.",London
# "Just watched Titanic, Leonardo DiCaprio's acting was amazing.",Chicago
# "Enjoying a lovely day in Paris.",Paris
# "Can't wait to visit the new Apple store.",San Francisco
# "I had a great experience at the hotel spa.",Miami
# "Discussions at the G20 are crucial for global cooperation.",London
# "Leonardo DiCaprio is my favorite actor.",Los Angeles
# "Missing the beautiful streets of Paris.",Paris

import pandas as pd
import matplotlib.pyplot as plt

file_path = 'twitter_location_data.csv'
df = pd.read_csv(file_path)

location_counts = df['location'].value_counts()

plt.figure(figsize=(10, 6))
location_counts.plot(kind='bar', color='skyblue')
plt.title('Distribution of Tweets by Location')
plt.xlabel('Location')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=45)
plt.show()

# HASHTAG POPULARITY
# CSV:
# tweet,hashtags
# "I love my new iPhone from Apple!","#happy #technology #Apple"
# "The hotel service was excellent during my stay.","#hotel #service #recommendation"
# "Excited for the upcoming G20 summit.","#G20 #politics #global"
# "Just watched Titanic, Leonardo DiCaprio's acting was amazing.","#movie #actor #LeonardoDiCaprio"
# "Enjoying a lovely day in Paris.","#Paris #travel #city"
# "Can't wait to visit the new Apple store.","#shopping #Apple #excited"
# "I had a great experience at the hotel spa.","#relaxation #spa #hotel"
# "Discussions at the G20 are crucial for global cooperation.","#G20 #discussion #global"
# "Leonardo DiCaprio is my favorite actor.","#actor #favorite #LeonardoDiCaprio"
# "Missing the beautiful streets of Paris.","#Paris #nostalgia #travel"

import pandas as pd

file_path = 'twitter_hashtag_data.csv'
df = pd.read_csv(file_path)

hashtags_list = df['hashtags'].str.split()

hashtags_count = {}
for hashtags in hashtags_list:
    for hashtag in hashtags:
        if hashtag.startswith('#'):
            hashtag = hashtag.lower()
            if hashtag in hashtags_count:
                hashtags_count[hashtag] += 1
            else:
                hashtags_count[hashtag] = 1

sorted_hashtags = sorted(hashtags_count.items(), key=lambda x: x[1], reverse=True)

print("Most popular hashtags:")
for hashtag, count in sorted_hashtags:
    print(f"{hashtag}: {count}")

#SENTIMENT
# import pandas as pd
# from textblob import TextBlob

# file_path = '/content/twitter.csv'
# df = pd.read_csv(file_path)

# sentiments = []
# for tweet in df['tweet']:
#     analysis = TextBlob(tweet)
#     polarity = analysis.sentiment.polarity
#     if polarity > 0:
#         sentiment = 'positive'
#     elif polarity < 0:
#         sentiment = 'negative'
#     else:
#         sentiment = 'neutral'
#     sentiments.append(sentiment)

# df['sentiment'] = sentiments

# print(df)


import pandas as pd

# Load the CSV file containing Twitter data
file_path = '/content/twitter.csv'  # Replace with the path to your CSV file
df = pd.read_csv(file_path)

# Define a function to classify sentiment
def classify_sentiment(text):
    # Predefined rules for sentiment classification
    positive_words = ['love', 'great', 'excellent', 'happy', 'excited', 'awesome']
    negative_words = ['hate', 'bad', 'terrible', 'disappointed', 'awful']

    # Tokenize the text and convert to lowercase
    words = text.lower().split()

    # Count positive and negative words
    positive_count = sum(1 for word in words if word in positive_words)
    negative_count = sum(1 for word in words if word in negative_words)

    # Classify sentiment
    if positive_count > negative_count:
        return 'positive'
    elif negative_count > positive_count:
        return 'negative'
    else:
        return 'neutral'

# Perform sentiment analysis on each tweet
sentiments = []
for tweet in df['tweet']:
    sentiment = classify_sentiment(tweet)
    sentiments.append(sentiment)

# Add the sentiment column to the DataFrame
df['sentiment'] = sentiments

# Display the DataFrame with sentiment analysis results
print(df)

# TWITTER + GOOGLE
# TWITTER DATA:
# tweet_id,tweet_text,user_id,user_location,created_at
# 1,"Great experience at XYZ store! #happy",1001,New York,2024-04-01
# 2,"Disappointed with the service at ABC restaurant. #unhappy",1002,Los Angeles,2024-04-02
# 3,"Just bought a new product from XYZ brand. #excited",1003,Chicago,2024-04-03
# 4,"Lovely weather today! #beautiful",1004,San Francisco,2024-04-04
# 5,"Attended the G20 summit. Interesting discussions. #G20",1005,Washington DC,2024-04-05

# GOOGLE DATA:
# review_id,review_text,user_id,user_location,rating,review_date
# 1,"Great food and service!",2001,New York,5,2024-03-30
# 2,"Disappointed with the quality.",2002,Los Angeles,2,2024-03-31
# 3,"Highly recommend this place!",2003,Chicago,5,2024-04-01
# 4,"Average experience.",2004,San Francisco,3,2024-04-02
# 5,"Excellent customer support.",2005,Miami,5,2024-04-03

# EXPLORATORY
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

twitter_df = pd.read_csv('dummy_twitter_data.csv')
google_reviews_df = pd.read_csv('dummy_google_reviews_data.csv')

plt.figure(figsize=(10, 6))
sns.countplot(data=twitter_df, x='user_location')
plt.title('Distribution of Tweets by User Location')
plt.xlabel('User Location')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=45)
plt.show()

plt.figure(figsize=(8, 5))
sns.countplot(data=google_reviews_df, x='rating')
plt.title('Distribution of Ratings')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.show()


#Brand Analysis (Twitter Sentiment Analysis):
from textblob import TextBlob

def analyze_sentiment(text):
    analysis = TextBlob(text)
    polarity = analysis.sentiment.polarity
    if polarity > 0:
        return 'positive'
    elif polarity < 0:
        return 'negative'
    else:
        return 'neutral'

twitter_df['sentiment'] = twitter_df['tweet_text'].apply(analyze_sentiment)

plt.figure(figsize=(8, 5))
sns.countplot(data=twitter_df, x='sentiment')
plt.title('Sentiment Analysis of Tweets')
plt.xlabel('Sentiment')
plt.ylabel('Count')
plt.show()


#User Engagement Analysis and Visualization:
import numpy as np

twitter_df['retweets'] = np.random.randint(0, 100, size=len(twitter_df))
twitter_df['likes'] = np.random.randint(0, 100, size=len(twitter_df))
twitter_df['replies'] = np.random.randint(0, 100, size=len(twitter_df))

plt.figure(figsize=(10, 6))
sns.barplot(data=twitter_df, x='tweet_id', y='retweets', color='skyblue', label='Retweets')
sns.barplot(data=twitter_df, x='tweet_id', y='likes', color='orange', label='Likes')
sns.barplot(data=twitter_df, x='tweet_id', y='replies', color='green', label='Replies')
plt.title('User Engagement Analysis')
plt.xlabel('Tweet ID')
plt.ylabel('Count')
plt.legend()
plt.show()

#SOCIAL NETWORK GRAPH
# import networkx as nx
# import matplotlib.pyplot as plt
# import random

# num_nodes = 20
# num_edges = 30
# G = nx.gnm_random_graph(num_nodes, num_edges)

# nx.draw(G, with_labels=True)
# plt.title('Random Social Network Graph')
# plt.show()

# # Degree Centrality
# degree_centrality = nx.degree_centrality(G)

# print("Degree Centrality:")
# for node, centrality in degree_centrality.items():
#     print(f"Node {node}: {centrality}")

import networkx as nx
import matplotlib.pyplot as plt

G = nx.Graph()

nodes = ["Alice", "Bob", "Charlie", "David", "Eve", "Frank", "Grace"]
G.add_nodes_from(nodes)

edges = [("Alice", "Bob"), ("Alice", "Charlie"), ("Alice", "David"),
         ("Bob", "David"), ("Bob", "Eve"), ("Charlie", "David"),
         ("David", "Eve"), ("David", "Frank"), ("Eve", "Frank"),
         ("Eve", "Grace")]
G.add_edges_from(edges)

nx.draw(G, with_labels=True)
plt.title('Social Network Graph')
plt.show()

# Degree Centrality
degree_centrality = nx.degree_centrality(G)

print("Degree Centrality:")
for node, centrality in degree_centrality.items():
    print(f"Node {node}: {centrality}")

# Betweenness Centrality
betweenness_centrality = nx.betweenness_centrality(G)

print("\nBetweenness Centrality:")
for node, centrality in betweenness_centrality.items():
    print(f"Node {node}: {centrality}")